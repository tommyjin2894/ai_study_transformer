{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어텐션\n",
    "\n",
    "- 어텐션층의 공간복잡도는 약 $n^2$ 이다<br>\n",
    "$n$ : 시퀀스 길이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 계산이 중요하다.\n",
    "- 규모의 법칙\n",
    "    - N, C, D 를 동시에 증가시키는 것이 더 나은 모델을 만드는 데 생산적이다.\n",
    "        - N: 모델 크기\n",
    "        - C: 컴퓨팅 예산\n",
    "        - D: 데이터 셋 크기\n",
    "\n",
    "- 거듭 제곱 법칙(power law)\n",
    "    - 언어 모델의 성능은 거듭 제곱 법칙을 따른다.\n",
    "        - 테스트 손실 $L(X) \\sim \\left( \\frac{1}{X} \\right)^{\\alpha}$\n",
    "\n",
    "- 샘플 효율성\n",
    "    - 대규모 모델은 적은 훈련횟수로도 소규모 모델과 동일한 성능을 낸다.\n",
    "        - 이미지, 비디오, 수학 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 규모확장의 어려움\n",
    "- 인프라\n",
    "    - GPU 가 여럿, 노드가 수백 수천 개를 관리하는 일은 쉽지 않다.\n",
    "    - 대규모 분산 을 능숙하게 해야한다.\n",
    "- 비용\n",
    "    - GPT-3 모델 하나 훈련시에 수백만 달러가 들기도 한다.\n",
    "    - GPT-4 훈련에 1억달러(약 1400억) 이상이 들었다\n",
    "- 고품질의 데이터셋\n",
    "    - 전처리의 어려움\n",
    "    - 고품질의 데이터셋인지 확인의 어려움\n",
    "    - 성차별, 편향 제어 방법 모색\n",
    "- 모델 평가\n",
    "    - 언어 모델 평가에 대한 시간과 자원\n",
    "    - 유해성 검증\n",
    "- 배포\n",
    "    - 대규모 모델을 서빙하는데 어려움\n",
    "    - 양자, 가지치기, 정제등의 모델 압축 및 경량화 기술이 있지만 충분치 않다.\n",
    "        - Openai Api, Accelerated Inference Api\n",
    "\n",
    "- BigScience, EleutherAI\n",
    "    - 오픈소스 연구 단체 들\n",
    "    - 여러 오픈소스 모델을 훈련하였고 배포함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다양한 어텐션 연구방향 https://arxiv.org/abs/2106.04554 (2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 희소 어텐션\n",
    "    - ![sparse attn](images/11_01.png)\n",
    "    - ![model](images/11_02.png)\n",
    "- 선형 어텐션\n",
    "    - ![linear attn](images/11_03.png)\n",
    "        - 기존 식 : $$ \\text{softmax}(\\frac{Q \\times K^T}{\\sqrt d_k}) \\times V$$\n",
    "        - 선형 식 : $$ \\phi(Q) \\times  (\\phi(K)^T \\times V)$$ 여기서 $\\phi$ 는 특성 변환 함수\n",
    "            - 특성 변환 함수 예시(피쳐 매핑) :\n",
    "                1. 가우시안 커널 근사 $\\phi(x) = e^x$\n",
    "                2. ReLU 변형 $\\phi(x) = \\text{max}(x,0)$\n",
    "    - 이러한 방식으로 복잡성이 $n^2$ -> $n$\n",
    "- 쿼리 프로토타이핑과 모델 압축\n",
    "    - ![qp_mc](images/11_04.png)\n",
    "- 로우랭크 self attention\n",
    "\n",
    "- 이외의 다양한 논문\n",
    "    - [A SURVEY ON TRANSFORMERS IN NLP WITH FOCUS ON EFFICIENCY](https://arxiv.org/pdf/2406.16893)\n",
    "    - [A Survey on Transformer Compression](https://arxiv.org/pdf/2402.05964)\n",
    "    - [AWQ: ACTIVATION-AWARE WEIGHT QUANTIZATION FOR ON-DEVICE LLM COMPRESSION AND ACCELERATION](https://arxiv.org/pdf/2306.00978)\n",
    "    - [DIFFERENTIAL TRANSFORMER](https://arxiv.org/pdf/2410.05258)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비전 트랜스 포머\n",
    "- iGPT (image GPT)\n",
    "    - 이미지의 픽셀을 시퀀스로 보고 GPT 모델구조와 자기회귀 를 이용해 훈련\n",
    "- ViT\n",
    "    - ![11_04](images/11_05.png)\n",
    "    - 이미지의 BERT 스타일의 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테이블 데이터\n",
    "- 쿼리와 결합한 트랜스 포머 아키텍쳐\n",
    "    - ![11_04](images/11_06.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 멀티 모달 트랜스 포머\n",
    "- 스피치 투 텍스트\n",
    "    - ![11_07](images/11_07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 비전 텍스트 모델\n",
    "    - VQA\n",
    "    - LayoutLM\n",
    "    - DALLE\n",
    "    - CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test for my self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWQ https://arxiv.org/pdf/2306.00978\n",
    "- Weight Quantization (AWQ)\n",
    "- [원본 모델 : aya-expanse-8b](https://huggingface.co/CohereForAI/aya-expanse-8b)\n",
    "- [weight 양자화 모델](https://huggingface.co/Orion-zhen/aya-expanse-8b-AWQ)\n",
    "- 16gb -> 약 6gb\n",
    "    - 8billion 모델을 약 5800MiB의 리소스로 사용 가능 하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have loaded an AWQ model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model.\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79321ba9826443e89fbed9a79d21ce3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "import huggingface_hub\n",
    "import torch\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_id = \"Orion-zhen/aya-expanse-8b-AWQ\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# 시작토큰 끝토큰 추가\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': ['<BOS_TOKEN>', '<EOS_TOKEN>']})\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "# 시작및 끝토큰을 모델 설정에 추가\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.bos_token_id = tokenizer.convert_tokens_to_ids('<BOS_TOKEN>')\n",
    "model.config.eos_token_id = tokenizer.convert_tokens_to_ids('<EOS_TOKEN>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "# CUDA가 사용 가능한 경우 GPU로 모델을 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "class CustomTextStreamer(TextStreamer):\n",
    "    def __init__(self, tokenizer):\n",
    "        super().__init__(tokenizer)\n",
    "\n",
    "    def on_finalized_text(self, text: str, stream_end: bool = False):\n",
    "        \"\"\"Prints the new text to stdout. If the stream is ending, also prints a newline.\"\"\"\n",
    "        print(text.replace(\"<BOS_TOKEN>\",\"\")\n",
    "              .replace(\"<EOS_TOKEN>\",\"\"), flush=True, end=\"\" if not stream_end else None)\n",
    "\n",
    "# 커스텀 텍스트 스트리밍\n",
    "textstreamer = CustomTextStreamer(tokenizer)\n",
    "\n",
    "# 파이프라인 생성 (text-generation 파이프라인으로 설정)\n",
    "gen_pipe = pipeline(\"text-generation\",\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    streamer = textstreamer,\n",
    "                    bos_token_id=tokenizer.convert_tokens_to_ids('<BOS_TOKEN>'),\n",
    "                    eos_token_id=tokenizer.convert_tokens_to_ids('<EOS_TOKEN>'),\n",
    "                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 더하기 함수 정의\n",
      "def sum(a,b):\n",
      "    return a + b\n",
      "\n",
      "# 함수 호출\n",
      "print(sum(3, 5))  # 출력: 8\n",
      "\n",
      "# 더하기 함수 재정의\n",
      "def sum(a,b,c):\n",
      "    return a + b + c\n",
      "\n",
      "# 함수 호출\n",
      "print(sum(1, 2, 3))  # 출력: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 메시지 정의\n",
    "messages = \"\"\"# 더하기 함수 정의\n",
    "def sum(a,b):\n",
    "    return\"\"\"\n",
    "\n",
    "# 텍스트 생성\n",
    "gen_text = gen_pipe(messages,\n",
    "                    do_sample=True,\n",
    "                    max_new_tokens=20000,\n",
    "                    top_k = 1,\n",
    "                    temperature=1.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
