{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë‹¤ì¤‘ì–¸ì–´ ê°œì²´ëª…ì¸ì‹\n",
    "\n",
    "- ì œë¡œìƒ· êµì°¨ ì–¸ì–´ ì „ì´ (zero-shot cross lingual switching) ê°€ëŠ¥\n",
    "  - í•œ ì–¸ì–´ì—ì„œ íŒŒì¸ íŠœë‹ëœ ëª¨ë¸ì´ í›ˆë ¨ì—†ì´ ë‹¤ë¥¸ ëª¨ë¸ì— ì ìš© ê°€ëŠ¥í•˜ë‹¤.\n",
    "- ì½”ë“œ ìŠ¤ìœ„ì¹­ ì— ì í•©\n",
    "  - í•˜ë‚˜ì˜ ëŒ€í™”ì—ì„œ ë‘˜ì´ìƒì˜ ì–¸ì–´ë‚˜, ì‚¬íˆ¬ë¦¬ë“±ì„ ë°”ê¿ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XTREME ë°ì´í„° ì…‹ ì´ìš©\n",
    "    - PAN-X, wikiANN : êµì°¨ ì–¸ì–´ ë°ì´í„° ì…‹\n",
    "    - LOC, PER, ORG\n",
    "    - IOB2 í¬ë§·\n",
    "        - i- ë™ì¼ ê°œì²´ëª…ì˜ ì—°ì†\n",
    "        - o- ì–´ë–¤ ê°œì²´ì—ë„ ì†í•˜ì§€ ì•ŠìŒ\n",
    "        - B- ê°œì²´ëª…ì˜ ì‹œì‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ì„œë¸Œì…‹ ê°¯ìˆ˜', 183)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "\"ì„œë¸Œì…‹ ê°¯ìˆ˜\",len(xtreme_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "af: PAN-X.af, ar: PAN-X.ar, \n",
      "bg: PAN-X.bg, bn: PAN-X.bn, de: PAN-X.de, el: PAN-X.el, en: PAN-X.en, \n",
      "es: PAN-X.es, et: PAN-X.et, eu: PAN-X.eu, fa: PAN-X.fa, fi: PAN-X.fi, \n",
      "fr: PAN-X.fr, he: PAN-X.he, hi: PAN-X.hi, hu: PAN-X.hu, id: PAN-X.id, \n",
      "it: PAN-X.it, ja: PAN-X.ja, jv: PAN-X.jv, ka: PAN-X.ka, kk: PAN-X.kk, \n",
      "ko: PAN-X.ko, ml: PAN-X.ml, mr: PAN-X.mr, ms: PAN-X.ms, my: PAN-X.my, \n",
      "nl: PAN-X.nl, pt: PAN-X.pt, ru: PAN-X.ru, sw: PAN-X.sw, ta: PAN-X.ta, \n",
      "te: PAN-X.te, th: PAN-X.th, tl: PAN-X.tl, tr: PAN-X.tr, ur: PAN-X.ur, \n",
      "vi: PAN-X.vi, yo: PAN-X.yo, zh: PAN-X.zh, "
     ]
    }
   ],
   "source": [
    "for i,l in enumerate(xtreme_subsets):\n",
    "    if \"PAN\" in l:\n",
    "        print(l.split(\".\")[-1], end=': ')\n",
    "        print(l, end=', ')\n",
    "        if i % 5 == 0:\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì–¸ì–´ ì„ íƒí•˜ê¸°\n",
    "\n",
    "- ì„ íƒ ì–¸ì–´\n",
    "    - PAN-X.en : ì˜ì–´\n",
    "    - PAN-X.ko : í•œêµ­ì–´\n",
    "    - PAN-X.ja : ì¼ë³¸ì–´\n",
    "    - PAN-X.es : ìŠ¤í˜ì¸ì–´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "from datasets import DatasetDict\n",
    "\n",
    "#ì¼ë°˜ì ì¸ ë¶ˆê· í˜• ìƒíƒœ ë§Œë“¤ê¸°\n",
    "langs = [\"en\", \"ko\", \"ja\", \"es\"]\n",
    "fracs = [0.12, 0.6, 0.8, 0.1]\n",
    "\n",
    "panx_ch = defaultdict(DatasetDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang, frac in zip(langs, fracs):\n",
    "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split]=(\n",
    "            ds[split]\n",
    "            .shuffle(seed=42)\n",
    "            .select(range(int(frac*ds[split].num_rows))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>ko</th>\n",
       "      <th>ja</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Samples</th>\n",
       "      <td>2400</td>\n",
       "      <td>12000</td>\n",
       "      <td>16000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           en     ko     ja    es\n",
       "Samples  2400  12000  16000  2000"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame({lang : [panx_ch[lang][\"train\"].num_rows] for lang in langs}, index=[\"Samples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens ['ã€ŠíŠ¸ì™€ì¼ë¼ì‡ã€‹ì„', 'ê°™ì´', 'ì°ì€', 'ì—ë””', 'ê°€í…Œì§€', ',', 'í¬ë¦¬ìŠ¤í‹´', 'ìŠ¤íŠœì–´íŠ¸', ',', 'ë¡œë²„íŠ¸', 'íŒ¨í‹´ìŠ¨ê³¼ëŠ”', 'ë§¤ìš°', 'ì¹œí•œì‚¬ì´ë¼ê³ ', 'í•œë‹¤', '.']\n",
      "ner_tags [0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0]\n",
      "langs ['ko', 'ko', 'ko', 'ko', 'ko', 'ko', 'ko', 'ko', 'ko', 'ko', 'ko', 'ko', 'ko', 'ko', 'ko']\n",
      "\n",
      "features ì¤‘ ner-íƒœê·¸ í™•ì¸\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element = panx_ch[\"ko\"][\"train\"][0]\n",
    "\n",
    "for k, v in element.items():\n",
    "    print(k,v)\n",
    "\n",
    "print(\"\\nfeatures ì¤‘ ner-íƒœê·¸ í™•ì¸\")\n",
    "ner_tags = panx_ch[\"ko\"][\"train\"].features[\"ner_tags\"].feature\n",
    "ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tag_names'],\n",
       "        num_rows: 12000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tag_names'],\n",
       "        num_rows: 6000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tag_names'],\n",
       "        num_rows: 6000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NER-íƒœê·¸ë¥¼ ì¸ë±ìŠ¤ ì—ì„œ íƒœê·¸ëª… ë³€ê²½ ë° ì¶”ê°€\n",
    "\n",
    "panx_ko = panx_ch[\"ko\"].map(lambda x : {\"ner_tag_names\" :\n",
    "                                        [ner_tags.int2str(idx)\n",
    "                                        for idx in x[\"ner_tags\"]]})\n",
    "panx_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>ã€ŠíŠ¸ì™€ì¼ë¼ì‡ã€‹ì„</td>\n",
       "      <td>ê°™ì´</td>\n",
       "      <td>ì°ì€</td>\n",
       "      <td>ì—ë””</td>\n",
       "      <td>ê°€í…Œì§€</td>\n",
       "      <td>,</td>\n",
       "      <td>í¬ë¦¬ìŠ¤í‹´</td>\n",
       "      <td>ìŠ¤íŠœì–´íŠ¸</td>\n",
       "      <td>,</td>\n",
       "      <td>ë¡œë²„íŠ¸</td>\n",
       "      <td>íŒ¨í‹´ìŠ¨ê³¼ëŠ”</td>\n",
       "      <td>ë§¤ìš°</td>\n",
       "      <td>ì¹œí•œì‚¬ì´ë¼ê³ </td>\n",
       "      <td>í•œë‹¤</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_tag_name</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0   1   2      3      4  5      6      7  8      9   \\\n",
       "tokens        ã€ŠíŠ¸ì™€ì¼ë¼ì‡ã€‹ì„  ê°™ì´  ì°ì€     ì—ë””    ê°€í…Œì§€  ,   í¬ë¦¬ìŠ¤í‹´   ìŠ¤íŠœì–´íŠ¸  ,    ë¡œë²„íŠ¸   \n",
       "ner_tag_name         O   O   O  B-PER  I-PER  O  B-PER  I-PER  O  B-PER   \n",
       "\n",
       "                 10  11      12  13 14  \n",
       "tokens        íŒ¨í‹´ìŠ¨ê³¼ëŠ”  ë§¤ìš°  ì¹œí•œì‚¬ì´ë¼ê³   í•œë‹¤  .  \n",
       "ner_tag_name  I-PER   O       O   O  O  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([panx_ko[\"train\"][0][\"tokens\"],\n",
    "              panx_ko[\"train\"][0][\"ner_tag_names\"]],\n",
    "              index=[\"tokens\",\"ner_tag_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê²°ê³¼: ì‚¬ëŒ ì´ë¦„ì— íƒœê·¸ê°€ ë¶™ì—ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### íƒœê·¸ ë¶„í¬ í™•ì¸í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'train': Counter({'LOC': 7097, 'ORG': 5361, 'PER': 4870}),\n",
       "             'validation': Counter({'LOC': 3579, 'ORG': 2755, 'PER': 2448}),\n",
       "             'test': Counter({'LOC': 3503, 'ORG': 2584, 'PER': 2557})})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "split2freqs = defaultdict(Counter)\n",
    "\n",
    "for split , dataset in panx_ko.items():\n",
    "    for row in dataset[\"ner_tag_names\"]:\n",
    "        for tag in row:\n",
    "            if tag.startswith(\"B\"):\n",
    "                tag_type = tag.split(\"-\")[1]\n",
    "                split2freqs[split][tag_type] += 1\n",
    "\n",
    "split2freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë‹¤ì¤‘ ì–¸ì–´ íŠ¸ëœìŠ¤ í¬ë¨¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì¼ë°˜ ì ìœ¼ë¡œ ë°ì´í„°ì…‹ì— ì—¬ëŸ¬ ì–¸ì–´ê°€ ìˆì–´ë„ ì¼ë°˜í™”ê°€ ê°€ëŠ¥í•˜ë‹¤.\n",
    "- ë‹¤ì¤‘ ì–¸ì–´ íŠ¸ëœìŠ¤ í¬ë¨¸ í‰ê°€ ë°©ë²•\n",
    "    1. **en (ì˜ì–´ í›ˆë ¨ í›„ í‰ê°€)**: ì˜ì–´ ë°ì´í„°ë¡œ í›ˆë ¨í•œ í›„ ë‹¤ë¥¸ ì–¸ì–´ì—ì„œ í‰ê°€.\n",
    "    2. **each (ë‹¨ì¼ í›ˆë ¨ ë° ë‹¨ì¼ í‰ê°€)**: ê° ì–¸ì–´ë³„ë¡œ ë³„ë„ë¡œ í›ˆë ¨í•˜ê³  í‰ê°€.\n",
    "    3. **all (ëª¨ë“  í›ˆë ¨ì…‹ì—ì„œ í‰ê°€)**: ëª¨ë“  ì–¸ì–´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ í›ˆë ¨í•˜ê³  ê° ì–¸ì–´ì—ì„œ í‰ê°€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLM-R(Cross-lingual LM)\n",
    "- RoBERTa ì˜ ë‹¤ì¤‘ ì–¸ì–´ ëª¨ë¸ ë²„ì ¼ : XLM-RoBERTa\n",
    "- 100ê°œ ì˜ ì–¸ì–´ë¡œ í›ˆë ¨\n",
    "\n",
    "- **SentencePiece** í† í¬ë‚˜ì´ì €\n",
    "    - Unigram(ë¶€ë¶„ ë‹¨ì–´ ë¶„í•  ë°©ì‹) ê¸°ë°˜ì˜ ì¸ì½”ë”© ë°©ì‹ì„ ì´ìš©\n",
    "    - íŠ¹ì • ì–¸ì–´ì— ëŒ€í•œ ì§€ì‹ì—†ì´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ê°€ëŠ¥\n",
    "    - ë‹¤êµ­ì–´ ë§ë­‰ì¹˜ì— ìœ ìš©í•˜ë‹¤\n",
    "    - ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ê³¼ í˜¸í™˜ì„±ì´ ì¢‹ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "bertmodel = \"bert-base-cased\"\n",
    "xlmrmodel = \"xlm-roberta-base\"\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bertmodel)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmrmodel) # Sentence Piece í† í¬ë‚˜ì´ì €"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'I', '##m', 'Your', 'Father', '[SEP]']\n",
      "['<s>', 'â–Im', 'â–Your', 'â–Father', '</s>']\n"
     ]
    }
   ],
   "source": [
    "text_test = \"Im Your Father\"\n",
    "\n",
    "print(bert_tokenizer.convert_ids_to_tokens(bert_tokenizer(text_test).input_ids))\n",
    "print(xlmr_tokenizer.convert_ids_to_tokens(xlmr_tokenizer(text_test).input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í† í°í™” íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "1. **ì •ê·œí™” (Normalization)**\n",
    "   - í…ìŠ¤íŠ¸ë¥¼ ì¼ê´€ëœ í˜•íƒœë¡œ ë³€í™˜.\n",
    "   - ì˜ˆ: `'Im Your Father'` â†’ `'im your father'`\n",
    "\n",
    "2. **ì‚¬ì „ í† í°í™” (Pre-tokenization)**\n",
    "   - ê³µë°±ê³¼ êµ¬ë‘ì ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì–´ë¡œ ë‚˜ëˆˆë‹¤..\n",
    "   - ì˜ˆ: `'im your father'` â†’ `['im', 'your', 'father']`\n",
    "\n",
    "3. **í† í¬ë‚˜ì´ì € ëª¨ë¸ (Tokenizer Model)**\n",
    "   - ë‹¨ì–´ë¥¼ ê³ ìœ í•œ ìˆ«ì IDë¡œ ë°”ê¿ˆ.\n",
    "   - ì˜ˆ: `['im', 'your', 'father']` â†’ `[125, 52, 482]`\n",
    "\n",
    "4. **ì‚¬í›„ì²˜ë¦¬ (Post-processing)**\n",
    "   - ì‹œì‘ê³¼ ëì„ ë‚˜íƒ€ë‚´ëŠ” íŠ¹ìˆ˜ í† í°ì„ ì¶”ê°€.\n",
    "   - ì˜ˆ: `[CLS] im your father [SEP]` â†’ `[0, 125, 52, 482, 1]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### íŠ¸ëœìŠ¤ í¬ë¨¸ ëª¨ë¸ í´ë˜ìŠ¤ì˜ í˜•ì‹\n",
    "![modelfortask](images/04_01.png)\n",
    "- `<ModelName>For<Task>` í˜•ì‹ì„ ë”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xtreme ë°ì´í„° ì…‹ -> ì»¤ë„ ì¢…ë£Œ í›„ ì•„ë˜ ì½”ë“œ ë¶€í„° ë‹¤ì‹œ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.ko', 'PAN-X.en', 'PAN-X.ja', 'PAN-X.es']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "# xtreme ë°ì´í„°ì…‹ ì´ë¦„ í™•ì¸\n",
    "subsets = get_dataset_config_names(\"xtreme\")\n",
    "\n",
    "def find_lan(lan):\n",
    "    return [j for j in [i for i in subsets if \"PAN-X\" in i]\n",
    "                if lan in j][0]\n",
    "\n",
    "language_names = [find_lan(l) for l in [\"ko\", \"en\", \"ja\", \"es\"]]\n",
    "language_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import DatasetDict, load_dataset\n",
    "\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "down_sample_ratios = [0.5, 0.3, 0.2, 0.1] #í˜„ì‹¤ ë°ì´í„° ì™€ ê°™ì´ ë°ì´í„° ë¶ˆê· í˜• ë§Œë“¤ê¸°\n",
    "# ë°ì´í„° ì…‹ ë¡œë“œ\n",
    "\n",
    "for l, down_sample_ratio in zip(language_names, down_sample_ratios):\n",
    "    l_name = (l.split('.')[-1])\n",
    "    down_sample = load_dataset(\"xtreme\", name=l)\n",
    "\n",
    "    for split in down_sample:\n",
    "        # ì„ íƒí•  ë°ì´í„° í¬ì¸íŠ¸ì˜ ìˆ˜\n",
    "        num_datas = int(down_sample[split].num_rows * down_sample_ratio)\n",
    "        panx_ch[l_name][split] = down_sample[split].shuffle(seed=42).select(range(num_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê° ì–¸ì–´ë³„ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ :\n",
      "[('ko', {'train': 10000, 'validation': 5000, 'test': 5000}), ('en', {'train': 6000, 'validation': 3000, 'test': 3000}), ('ja', {'train': 4000, 'validation': 2000, 'test': 2000}), ('es', {'train': 2000, 'validation': 1000, 'test': 1000})]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"ê° ì–¸ì–´ë³„ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ :\n",
    "{[(j,panx_ch[j].num_rows) for j in [i for i in panx_ch]]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC'} \n",
      " {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n"
     ]
    }
   ],
   "source": [
    "labels = panx_ch[\"ko\"][\"train\"].features[\"ner_tags\"].feature.names\n",
    "\n",
    "i2l = {k:v for k,v in enumerate(labels)}\n",
    "l2i = {v:k for k,v in enumerate(labels)}\n",
    "\n",
    "print(i2l,\"\\n\",l2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë¼ë²¨ ë§µí•‘í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags_str = lambda bs : {\"ner_tags_str\" :([[i2l[i] for i in b] for b in bs[\"ner_tags\"]])}\n",
    "\n",
    "for l in [\"ko\", \"en\", \"ja\", \"es\"]:\n",
    "    panx_ch[l] = (panx_ch[l]\n",
    "                    .map(ner_tags_str,\n",
    "                    batch_size= 100, batched=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>Jake</td>\n",
       "      <td>McGee</td>\n",
       "      <td>,</td>\n",
       "      <td>current</td>\n",
       "      <td>MLB</td>\n",
       "      <td>player</td>\n",
       "      <td>(</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>Bay</td>\n",
       "      <td>Rays</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_tags</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>langs</th>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_tags_str</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0      1   2        3      4       5   6      7      8   \\\n",
       "tokens         Jake  McGee   ,  current    MLB  player   (  Tampa    Bay   \n",
       "ner_tags          1      2   0        0      3       0   0      3      4   \n",
       "langs            en     en  en       en     en      en  en     en     en   \n",
       "ner_tags_str  B-PER  I-PER   O        O  B-ORG       O   O  B-ORG  I-ORG   \n",
       "\n",
       "                 9   10  \n",
       "tokens         Rays   )  \n",
       "ner_tags          4   0  \n",
       "langs            en  en  \n",
       "ner_tags_str  I-ORG   O  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(panx_ch[\"en\"][\"train\"][122]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ko ì•ˆì˜ ner ê°¯ ìˆ˜ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [4097, 4495, 5845],\n",
       " 'validation': [2039, 2297, 2976],\n",
       " 'test': [2116, 2165, 2971]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_count = {}\n",
    "for k in [\"train\", \"validation\", \"test\"]:\n",
    "    all_content =[]\n",
    "    for i in panx_ch['ko'][k][\"ner_tags_str\"]:\n",
    "        for j in i:\n",
    "            if \"B\" in j:\n",
    "                all_content.append(j.split(\"-\")[-1])\n",
    "        per , org, loc =(all_content.count('PER'),\n",
    "                         all_content.count('ORG'),\n",
    "                         all_content.count('LOC'))\n",
    "        all_count[k] = [per, org, loc]\n",
    "all_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PER</th>\n",
       "      <th>ORG</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>4097</td>\n",
       "      <td>4495</td>\n",
       "      <td>5845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>2039</td>\n",
       "      <td>2297</td>\n",
       "      <td>2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2116</td>\n",
       "      <td>2165</td>\n",
       "      <td>2971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PER   ORG   LOC\n",
       "train       4097  4495  5845\n",
       "validation  2039  2297  2976\n",
       "test        2116  2165  2971"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_count,\n",
    "              index=['PER', 'ORG', 'LOC']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLM-R í† í¬ë‚˜ì´ì €"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë„˜ê²¨ì£¼ê¸° ë¬´ëª… ìš©ì‚¬ì˜ ë¬´ë¤'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(panx_ch['ko']['train'][1266][\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 11873, 2293, 6, 166637, 71393, 16907, 12286, 80169, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokenizer(' '.join(panx_ch['ko']['train'][4][\"tokens\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 17:04:33.326184: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732521873.371438   68184 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732521873.385261   68184 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-25 17:04:33.484245: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel, RobertaPreTrainedModel\n",
    "\n",
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels # ë¼ë²¨ ìˆ˜\n",
    "        # ëª¨ë¸ ë°”ë”” ë¡œë“œ\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        # ë¶„ë¥˜ í—¤ë“œ\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None,\n",
    "                token_type_ids=None, **kwargs):\n",
    "        # ì¸ì½”ë” ì•„ì›ƒí’‹\n",
    "        outputs = self.roberta(input_ids,\n",
    "                               attention_mask = attention_mask,\n",
    "                               token_type_ids=token_type_ids, **kwargs)\n",
    "        # ì•„ì›ƒí’‹ -> í—¤ë“œ\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        \n",
    "        # ì†ì‹¤ ê³„ì‚°\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        # ëª¨ë¸ ì¶œë ¥ ë°˜í™˜\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits,\n",
    "                                     hidden_states=outputs.hidden_states,\n",
    "                                     attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name,\n",
    "                                         num_labels = len(labels),\n",
    "                                         id2label = i2l,\n",
    "                                         label2id = l2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "xlmr_model = (XLMRobertaForTokenClassification\n",
    "              .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "              .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>â–this</td>\n",
       "      <td>â–is</td>\n",
       "      <td>â–test</td>\n",
       "      <td>,</td>\n",
       "      <td>â–here</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1    2      3  4      5     6\n",
       "tokens  <s>  â–this  â–is  â–test  ,  â–here  </s>\n",
       "tags      O      O    O      O  O      O     O"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "    # í† í¬ë‚˜ì´ì§•\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    \n",
    "    # seq 2 input_ids\n",
    "    input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "    # logits\n",
    "    outputs = model(input_ids)[0]\n",
    "\n",
    "    # ê°€ì¥ í™•ìœ¨ë†’ì€ í´ë˜ìŠ¤ ì„ íƒ\n",
    "    predictions = torch.argmax(outputs, dim=2)\n",
    "\n",
    "    # to df\n",
    "    preds = [tags[p] for p in predictions[0]]\n",
    "    return pd.DataFrame([tokens, preds], index=[\"tokens\",\"tags\"])\n",
    "\n",
    "tag_text(\"this is test, here\", labels, xlmr_model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ch['ko']['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í† í¬ë‚˜ì´ì§•, ì–´í…ì…˜ ë§ˆìŠ¤í¬, ë¼ë²¨ ì •ë¦¬\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_input = xlmr_tokenizer(examples[\"tokens\"], truncation=True,\n",
    "                                     is_split_into_words=True)\n",
    "\n",
    "    labels=[]\n",
    "    for idx, label in enumerate(examples[\"ner_tags\"]):\n",
    "        # print(examples['tokens'][idx],label)\n",
    "        word_ids = tokenized_input.word_ids(batch_index=idx)\n",
    "        # print(word_ids)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # print(word_idx)\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "        labels.append(label_ids)\n",
    "    tokenized_input[\"labels\"] = labels\n",
    "    return tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì¸í’‹ê°’ ì •ì œí•˜ê¸°\n",
    "def encode_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels, batched=True,\n",
    "                      remove_columns=[\"langs\", \"ner_tags\", \"tokens\", \"ner_tags_str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8231d54db8845468c6b644b9be24c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8164b173cb41a6b5699d9ef7b03962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bc206a7b7a4c0ab7843909322407c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_ko =encode_dataset(panx_ch[\"ko\"])\n",
    "encoded_ko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLM-RoBERTa íŒŒì¸íŠœë‹ í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tommy/anaconda3/envs/transformer/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epoch = 3\n",
    "batch_size = 24\n",
    "logging_steps = len(encoded_ko[\"train\"]) // batch_size\n",
    "model_name = f\"{xlmr_model_name}-finetuned-panx-ko\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    log_level=\"error\",\n",
    "    num_train_epochs=num_epoch,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_steps=1e6, weight_decay=0.01, disable_tqdm=False,\n",
    "    logging_steps=logging_steps, push_to_hub=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def align_preds(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    label_list, preds_list = [],[]\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [],[]\n",
    "        for seq_idx in range(seq_len):\n",
    "            if label_ids[batch_idx, seq_idx] != -100: # <s> ë° </s> ë¬´ì‹œ\n",
    "                example_labels.append(i2l[label_ids[batch_idx][seq_idx]])\n",
    "                example_preds.append(i2l[preds[batch_idx][seq_idx]])\n",
    "        label_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "    \n",
    "    return preds_list, label_list\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_pred, y_true = align_preds(eval_pred.predictions,\n",
    "                                 eval_pred.label_ids)\n",
    "    return {\"f1_score\" : f1_score(y_pred,y_true)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë°ì´í„° ì½œë ˆì´í„°(Data Collator)\n",
    "    - ë°ì´í„° ì½œë ˆì´í„°ëŠ” ë°ì´í„°ì…‹ ìš”ì†Œë“¤ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ë°°ì¹˜ë¥¼ í˜•ì„±í•˜ëŠ” ê°ì²´.\n",
    "    - ì´ëŸ¬í•œ ìš”ì†Œë“¤ì€ train_dataset ë˜ëŠ” eval_datasetì˜ ìš”ì†Œë“¤ê³¼ ë™ì¼í•œ íƒ€ì….\n",
    "    - ë°°ì¹˜ë¥¼ êµ¬ì„±í•˜ê¸° ìœ„í•´ ë°ì´í„° ì½œë ˆì´í„°ëŠ” íŒ¨ë”©ê³¼ ê°™ì€ ì²˜ë¦¬ë¥¼ ì ìš©í•  ìˆ˜ ìˆë‹¤.\n",
    "    - DataCollatorForLanguageModelingê³¼ ê°™ì€ ì¼ë¶€ ì½œë ˆì´í„°ëŠ” í˜•ì„±ëœ ë°°ì¹˜ì— ë¬´ì‘ìœ„ ë§ˆìŠ¤í‚¹ê³¼ ê°™ì€ ì¼ë¶€ ë¬´ì‘ìœ„ ë°ì´í„° ì¦ê°•ì„ ì ìš©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification # ì…ë ¥ê³¼ ë ˆì´ë¸” íŒ¨ë”© ì „ìš© ì½œë ˆì´í„°\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_init í•¨ìˆ˜ : ëª¨ë¸ ì¬ì‚¬ìš©ì„ ìœ„í•œ ëª¨ë¸ ìƒì„± í•¨ìˆ˜ì •ì˜\n",
    "def model_init():\n",
    "    return (XLMRobertaForTokenClassification\n",
    "            .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "            .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_68184/2119604388.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model_init=model_init,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1251' max='1251' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1251/1251 08:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.454700</td>\n",
       "      <td>0.271479</td>\n",
       "      <td>0.821335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>0.244721</td>\n",
       "      <td>0.847851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>0.226946</td>\n",
       "      <td>0.864984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1251, training_loss=0.2776064072533858, metrics={'train_runtime': 501.7434, 'train_samples_per_second': 59.792, 'train_steps_per_second': 2.493, 'total_flos': 835350415434480.0, 'train_loss': 0.2776064072533858, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë“  ê°ì²´ë¥¼ trainer ì— ì „ë‹¬\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model_init=model_init,\n",
    "                  args=training_args,\n",
    "                  data_collator=data_collator,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=encoded_ko[\"train\"],\n",
    "                  eval_dataset=encoded_ko[\"validation\"],\n",
    "                  tokenizer = xlmr_tokenizer)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.push_to_hub(commit_message=\"first training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>â–ì•ˆë…•í•˜ì„¸ìš”</td>\n",
       "      <td>â–ì €ëŠ”</td>\n",
       "      <td>â–ì„œìš¸</td>\n",
       "      <td>ì—</td>\n",
       "      <td>â–ì‚´ê³ </td>\n",
       "      <td>â–ìˆìŠµë‹ˆë‹¤</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1    2      3      4    5      6  7  8     9\n",
       "tokens  <s>  â–ì•ˆë…•í•˜ì„¸ìš”  â–ì €ëŠ”    â–ì„œìš¸      ì—  â–ì‚´ê³   â–ìˆìŠµë‹ˆë‹¤  .  .  </s>\n",
       "tags      O       O    O  B-LOC  B-LOC    O      O  O  O     O"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "test_massage = \"ì•ˆë…•í•˜ì„¸ìš” ì €ëŠ” ì„œìš¸ì— ì‚´ê³  ìˆìŠµë‹ˆë‹¤..\"\n",
    "tag_text(test_massage,\n",
    "         labels, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•œ ë¶„ì„\n",
    "def forward_pass_with_label(batch):\n",
    "    # batch to dict\n",
    "    features = [dict(zip(batch,t)) for t in zip(*batch.values())]\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "\n",
    "    # ì¶”ë¡  ëª¨ë“œ\n",
    "    with torch.no_grad():\n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        predicted_label = torch.argmax(output.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "    # ë°°ì¹˜ë§ˆë‹¤ ì†ì‹¤ ê³„ì‚°\n",
    "    # í•˜ë‚˜ì˜ í† í°ë§ˆë‹¤ 7ê°œì˜ í™•ë¥ ì´ ë‚˜ì˜¤ë¯€ë¡œ ê° ì¶œë ¥ë§ˆë‹¤ í•˜ë‚˜ì˜ í…ì„œë¡œ\n",
    "    # ì¦‰ ì •ë‹µ ë¼ë²¨ 1ê°œ, ì¶œë ¥ê°’ 7ê°œ ì— ëŒ€í•œ cross entropy loss ê°’ì´ ë‚˜ì˜¨ë‹¤.\n",
    "    loss = cross_entropy(output.logits.view(-1,7),\n",
    "                         labels.view(-1), reduction=\"none\")\n",
    "\n",
    "    # loss ê³„ì‚°í›„ ê° ì‹œí€€ìŠ¤ë³„ ë¬¶ê¸°\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "    return {\"loss\":loss, \"predicted_label\": predicted_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e423c4dd92c4e7c9423fd8b4e3bfcb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ê²€ì¦ ë°ì´í„° ë°°ì¹˜ë³„ ë§¤í•‘\n",
    "valid_result = encoded_ko['validation'].map(forward_pass_with_label, batch_size=32, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2l[-100] = \"IGN\" # í• ë‹¹ <s>,</s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(valid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ì‹œ index to token\n",
    "df_result[\"input_tokens\"] = df_result[\"input_ids\"].apply(\n",
    "    lambda x : xlmr_tokenizer.convert_ids_to_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[\"predicted_label\"] = df_result[\"predicted_label\"].apply(\n",
    "    lambda x : [i2l[i] for i in x])\n",
    "\n",
    "df_result[\"labels\"] = df_result[\"labels\"].apply(\n",
    "    lambda x : [i2l[i] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›ë˜ í¬ê¸°ì— ë§ì¶°ì„œ íŒ¨ë”© ìë¥´ê¸°\n",
    "df_result['loss'] = df_result.apply(\n",
    "    lambda x : x['loss'][:len(x['input_ids'])], axis=1)\n",
    "\n",
    "df_result[\"predicted_label\"] = df_result.apply(\n",
    "    lambda x : x[\"predicted_label\"][:len(x['input_ids'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 6339, 16295, 2099, 7286, 3999, 769, 96897,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, O, O, O, O, O, O, B-LOC, B-LOC, I-LOC, I...</td>\n",
       "      <td>[0.0, 0.0008671099785715342, 0.001348301419056...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-LOC, B-LOC, I-LOC, I-L...</td>\n",
       "      <td>[&lt;s&gt;, â–ì§€, ì²­, ì‚¬, ë¬´, ì†Œ, ëŠ”, â–ì•„ë§ˆ, ë¯¸, â–, ì‹œì—, â–ìœ„ì¹˜í•œ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 61805, 23854, 167427, 11031, 7286, 6521, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, O, O, O, B-ORG, B-ORG, I-ORG, I-ORG, I-O...</td>\n",
       "      <td>[0.0, 0.00034791138023138046, 0.00037222131504...</td>\n",
       "      <td>[O, O, O, O, B-ORG, B-ORG, I-ORG, I-ORG, I-ORG...</td>\n",
       "      <td>[&lt;s&gt;, â–ë„˜, ê²¨, ì£¼ê¸°, â–ìƒ, ë¬´, â–ì‹ , í˜‘, â–ë°°, êµ¬, ë‹¨, &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 7063, 8333, 123870, 15, 106, 6192, 6780, 7...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-PER, B-PER, B-PER, O, O, O, O, O, O, O...</td>\n",
       "      <td>[0.0, 0.006986474618315697, 0.0048017664812505...</td>\n",
       "      <td>[O, B-PER, B-PER, B-PER, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[&lt;s&gt;, â–ì •, í˜•, ëˆ, â–(, â–1, íšŒ, â–~, â–24, íšŒ, â–), &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 79978, 96648, 28185, 63993, 697, 97670, 16...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[IGN, O, O, O, O, O, O, O, O, O, B-ORG, B-ORG,...</td>\n",
       "      <td>[0.0, 0.0003415954706724733, 0.000439785566413...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-ORG, B-ORG, B...</td>\n",
       "      <td>[&lt;s&gt;, â–ê·¸ì˜, â–ì‹œì¦Œ, â–ì²«, â–ê³¨, ì€, â–3-0, ìœ¼ë¡œ, â–ì´, ê¸´, â–,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 242, 5106, 23526, 12057, 5106, 242, 769, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[IGN, O, O, B-LOC, B-LOC, O, O, O, B-LOC, B-LO...</td>\n",
       "      <td>[0.0, 0.00037126801908016205, 0.00037567710387...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-LOC, B-LOC, B-LOC, ...</td>\n",
       "      <td>[&lt;s&gt;, â–', â–'', â–ìš°, íŒŒ, â–'', â–', ëŠ”, â–ëŸ¬ì‹œì•„, â–ë°”, ì‹œí‚¤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>[0, 101278, 6, 106286, 367, 6, 237558, 12788, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[IGN, B-ORG, I-ORG, I-ORG, I-ORG, O, O, O, O, ...</td>\n",
       "      <td>[0.0, 0.4214648902416229, 0.3684261739253998, ...</td>\n",
       "      <td>[O, B-ORG, I-ORG, I-ORG, I-ORG, O, O, O, O, O,...</td>\n",
       "      <td>[&lt;s&gt;, â–ìœ ëŸ½, â–, ì—°í•©, ì˜, â–, ê¹ƒ, ë°œ, ì—ëŠ”, â–12, ê°œì˜, â–ë³„,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>[0, 8237, 9187, 46364, 15, 33892, 84386, 713, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-PER, B-PER, B-PER, I-PER, I-PER, I-PER...</td>\n",
       "      <td>[0.0, 0.008504010736942291, 0.0070904060266911...</td>\n",
       "      <td>[O, B-PER, B-PER, B-PER, I-PER, I-PER, I-PER, ...</td>\n",
       "      <td>[&lt;s&gt;, â–ê¹€, í•™, ìˆœ, â–(, â–ì—¬ì„±, ìš´ë™, ê°€, â–), &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>[0, 44486, 6308, 3497, 8495, 1048, 5807, 10693...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-PER, B-PER, B-PER, B-PER, B-PER, I-PER...</td>\n",
       "      <td>[0.0, 0.005169240292161703, 0.0046163178049027...</td>\n",
       "      <td>[O, B-PER, B-PER, B-PER, B-PER, B-PER, I-PER, ...</td>\n",
       "      <td>[&lt;s&gt;, â–ë ˆ, ì˜¤, ë‚˜, ë¥´, ë„, â–ë³´, ëˆ„, ì¹˜, â–(, â–34, â–), &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>[0, 13745, 26141, 11289, 45504, 26191, 45981, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[IGN, O, O, O, O, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[0.0, 0.003446117974817753, 0.0061222868971526...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[&lt;s&gt;, â–ë°œ, íš¨, í•˜ì§€, â–ì•Šê³ , â–í™”, ë•, ì—, â–êµ¬, ìš´, â–, ë‚©, ì‘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>[0, 1504, 1083, 115676, 1504, 26141, 40771, 16...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, O, O, O, B-PER, B-PER, B-PER, O, O, O, O...</td>\n",
       "      <td>[0.0, 0.000390215078368783, 0.0004285847535356...</td>\n",
       "      <td>[O, O, O, O, B-PER, B-PER, B-PER, O, O, O, O, ...</td>\n",
       "      <td>[&lt;s&gt;, â–ì´, ë¡œ, â–ì¸í•´, â–ì´, íš¨, ë¦¬ëŠ”, â–í™œë™ì„, â–ì„, ì‹œ, â–ì¤‘ë‹¨,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_ids  \\\n",
       "0     [0, 6339, 16295, 2099, 7286, 3999, 769, 96897,...   \n",
       "1     [0, 61805, 23854, 167427, 11031, 7286, 6521, 5...   \n",
       "2     [0, 7063, 8333, 123870, 15, 106, 6192, 6780, 7...   \n",
       "3     [0, 79978, 96648, 28185, 63993, 697, 97670, 16...   \n",
       "4     [0, 242, 5106, 23526, 12057, 5106, 242, 769, 1...   \n",
       "...                                                 ...   \n",
       "4995  [0, 101278, 6, 106286, 367, 6, 237558, 12788, ...   \n",
       "4996  [0, 8237, 9187, 46364, 15, 33892, 84386, 713, ...   \n",
       "4997  [0, 44486, 6308, 3497, 8495, 1048, 5807, 10693...   \n",
       "4998  [0, 13745, 26141, 11289, 45504, 26191, 45981, ...   \n",
       "4999  [0, 1504, 1083, 115676, 1504, 26141, 40771, 16...   \n",
       "\n",
       "                                         attention_mask  \\\n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "1                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "2                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "4995  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4996                     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "4997            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "4998  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4999      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                                 labels  \\\n",
       "0     [IGN, O, O, O, O, O, O, B-LOC, B-LOC, I-LOC, I...   \n",
       "1     [IGN, O, O, O, B-ORG, B-ORG, I-ORG, I-ORG, I-O...   \n",
       "2     [IGN, B-PER, B-PER, B-PER, O, O, O, O, O, O, O...   \n",
       "3     [IGN, O, O, O, O, O, O, O, O, O, B-ORG, B-ORG,...   \n",
       "4     [IGN, O, O, B-LOC, B-LOC, O, O, O, B-LOC, B-LO...   \n",
       "...                                                 ...   \n",
       "4995  [IGN, B-ORG, I-ORG, I-ORG, I-ORG, O, O, O, O, ...   \n",
       "4996  [IGN, B-PER, B-PER, B-PER, I-PER, I-PER, I-PER...   \n",
       "4997  [IGN, B-PER, B-PER, B-PER, B-PER, B-PER, I-PER...   \n",
       "4998  [IGN, O, O, O, O, O, O, O, O, O, O, O, O, O, O...   \n",
       "4999  [IGN, O, O, O, B-PER, B-PER, B-PER, O, O, O, O...   \n",
       "\n",
       "                                                   loss  \\\n",
       "0     [0.0, 0.0008671099785715342, 0.001348301419056...   \n",
       "1     [0.0, 0.00034791138023138046, 0.00037222131504...   \n",
       "2     [0.0, 0.006986474618315697, 0.0048017664812505...   \n",
       "3     [0.0, 0.0003415954706724733, 0.000439785566413...   \n",
       "4     [0.0, 0.00037126801908016205, 0.00037567710387...   \n",
       "...                                                 ...   \n",
       "4995  [0.0, 0.4214648902416229, 0.3684261739253998, ...   \n",
       "4996  [0.0, 0.008504010736942291, 0.0070904060266911...   \n",
       "4997  [0.0, 0.005169240292161703, 0.0046163178049027...   \n",
       "4998  [0.0, 0.003446117974817753, 0.0061222868971526...   \n",
       "4999  [0.0, 0.000390215078368783, 0.0004285847535356...   \n",
       "\n",
       "                                        predicted_label  \\\n",
       "0     [O, O, O, O, O, O, O, B-LOC, B-LOC, I-LOC, I-L...   \n",
       "1     [O, O, O, O, B-ORG, B-ORG, I-ORG, I-ORG, I-ORG...   \n",
       "2      [O, B-PER, B-PER, B-PER, O, O, O, O, O, O, O, O]   \n",
       "3     [O, O, O, O, O, O, O, O, O, O, B-ORG, B-ORG, B...   \n",
       "4     [O, O, O, O, O, O, O, O, B-LOC, B-LOC, B-LOC, ...   \n",
       "...                                                 ...   \n",
       "4995  [O, B-ORG, I-ORG, I-ORG, I-ORG, O, O, O, O, O,...   \n",
       "4996  [O, B-PER, B-PER, B-PER, I-PER, I-PER, I-PER, ...   \n",
       "4997  [O, B-PER, B-PER, B-PER, B-PER, B-PER, I-PER, ...   \n",
       "4998  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "4999  [O, O, O, O, B-PER, B-PER, B-PER, O, O, O, O, ...   \n",
       "\n",
       "                                           input_tokens  \n",
       "0     [<s>, â–ì§€, ì²­, ì‚¬, ë¬´, ì†Œ, ëŠ”, â–ì•„ë§ˆ, ë¯¸, â–, ì‹œì—, â–ìœ„ì¹˜í•œ, ...  \n",
       "1        [<s>, â–ë„˜, ê²¨, ì£¼ê¸°, â–ìƒ, ë¬´, â–ì‹ , í˜‘, â–ë°°, êµ¬, ë‹¨, </s>]  \n",
       "2      [<s>, â–ì •, í˜•, ëˆ, â–(, â–1, íšŒ, â–~, â–24, íšŒ, â–), </s>]  \n",
       "3     [<s>, â–ê·¸ì˜, â–ì‹œì¦Œ, â–ì²«, â–ê³¨, ì€, â–3-0, ìœ¼ë¡œ, â–ì´, ê¸´, â–,...  \n",
       "4     [<s>, â–', â–'', â–ìš°, íŒŒ, â–'', â–', ëŠ”, â–ëŸ¬ì‹œì•„, â–ë°”, ì‹œí‚¤...  \n",
       "...                                                 ...  \n",
       "4995  [<s>, â–ìœ ëŸ½, â–, ì—°í•©, ì˜, â–, ê¹ƒ, ë°œ, ì—ëŠ”, â–12, ê°œì˜, â–ë³„,...  \n",
       "4996          [<s>, â–ê¹€, í•™, ìˆœ, â–(, â–ì—¬ì„±, ìš´ë™, ê°€, â–), </s>]  \n",
       "4997  [<s>, â–ë ˆ, ì˜¤, ë‚˜, ë¥´, ë„, â–ë³´, ëˆ„, ì¹˜, â–(, â–34, â–), <...  \n",
       "4998  [<s>, â–ë°œ, íš¨, í•˜ì§€, â–ì•Šê³ , â–í™”, ë•, ì—, â–êµ¬, ìš´, â–, ë‚©, ì‘...  \n",
       "4999  [<s>, â–ì´, ë¡œ, â–ì¸í•´, â–ì´, íš¨, ë¦¬ëŠ”, â–í™œë™ì„, â–ì„, ì‹œ, â–ì¤‘ë‹¨,...  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6339</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>O</td>\n",
       "      <td>â–ì§€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16295</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>O</td>\n",
       "      <td>ì²­</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2099</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>O</td>\n",
       "      <td>ì‚¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7286</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>O</td>\n",
       "      <td>ë¬´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3999</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>O</td>\n",
       "      <td>ì†Œ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2166</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>O</td>\n",
       "      <td>ì‹œ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>206276</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>O</td>\n",
       "      <td>â–ì¤‘ë‹¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>50751</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>O</td>\n",
       "      <td>í•˜ì˜€ë‹¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>O</td>\n",
       "      <td>â–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89119 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     input_ids attention_mask labels      loss predicted_label input_tokens\n",
       "0         6339              1      O  0.000867               O           â–ì§€\n",
       "0        16295              1      O  0.001348               O            ì²­\n",
       "0         2099              1      O  0.001185               O            ì‚¬\n",
       "0         7286              1      O  0.001066               O            ë¬´\n",
       "0         3999              1      O  0.001376               O            ì†Œ\n",
       "...        ...            ...    ...       ...             ...          ...\n",
       "4999      2166              1      O  0.000398               O            ì‹œ\n",
       "4999    206276              1      O  0.000371               O          â–ì¤‘ë‹¨\n",
       "4999     50751              1      O  0.000279               O          í•˜ì˜€ë‹¤\n",
       "4999         6              1      O  0.000228               O            â–\n",
       "4999         5              1      O  0.000276               O            .\n",
       "\n",
       "[89119 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì¸ë±ìŠ¤ ê° í† í°ë³„ ë¶„í•´\n",
    "df_tokens = df_result.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens[df_tokens[\"labels\"] != \"IGN\"] # IGNì€ ì˜ˆì¸¡ loss ì—ì„œ ë¹¼ê¸°\n",
    "df_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6505</td>\n",
       "      <td>53513</td>\n",
       "      <td>6374</td>\n",
       "      <td>6025</td>\n",
       "      <td>9839</td>\n",
       "      <td>4596</td>\n",
       "      <td>2267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.766222</td>\n",
       "      <td>0.085303</td>\n",
       "      <td>0.482868</td>\n",
       "      <td>0.454054</td>\n",
       "      <td>0.20701</td>\n",
       "      <td>0.35287</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>4984.272879</td>\n",
       "      <td>4564.80906</td>\n",
       "      <td>3077.798421</td>\n",
       "      <td>2735.678038</td>\n",
       "      <td>2036.774456</td>\n",
       "      <td>1621.78849</td>\n",
       "      <td>1179.816505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0           1            2            3            4  \\\n",
       "labels        B-ORG           O        I-ORG        B-PER        B-LOC   \n",
       "count          6505       53513         6374         6025         9839   \n",
       "mean       0.766222    0.085303     0.482868     0.454054      0.20701   \n",
       "sum     4984.272879  4564.80906  3077.798421  2735.678038  2036.774456   \n",
       "\n",
       "                 5            6  \n",
       "labels       I-PER        I-LOC  \n",
       "count         4596         2267  \n",
       "mean       0.35287     0.520431  \n",
       "sum     1621.78849  1179.816505  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"labels\")[[\"loss\"]]\n",
    "    .agg([\"count\",\"mean\",\"sum\"])\n",
    "    .droplevel(level=0, axis=1) # ë©€í‹° ì»¬ëŸ¼ ì‚­ì œ\n",
    "    .sort_values(by=\"sum\", ascending=False)\n",
    "    .reset_index()\n",
    "    .head(10)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- B-ORG ì˜ í‰ê·  ì†ì‹¤ì´ ê°€ì¥ ë†’ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì œë¡œìƒ· ì „ì´ : êµì°¨ ì–¸ì–´ ì „ì´í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(trainer, dataset):\n",
    "    return trainer.predict(dataset).metrics[\"test_f1_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a1fbe95b564ad191d3e05cd4cd06d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027de59a45a74f03aacc351b14f781b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afef92fbf6b04bdda7c27ee6b9b4de28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_en = encode_dataset(panx_ch[\"en\"])\n",
    "encoded_ja = encode_dataset(panx_ch[\"ja\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5389431167956916"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_f1_score(trainer ,encoded_en[\"valiation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20663811563169163"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_f1_score(trainer ,encoded_ja[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 06:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.153000</td>\n",
       "      <td>1.082186</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.914000</td>\n",
       "      <td>1.007886</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.815800</td>\n",
       "      <td>0.922073</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1e7433272e49a9846c34627bd0c31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1732539057.DESKTOP-2KLMMI4.68184.3:   0%|          | 0.00/7.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sample</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_sample  f1_score\n",
       "0         250       0.0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_on_subset(dataset, num_samples):\n",
    "    train_ds = dataset[\"train\"].shuffle(seed=42).select(range(num_samples))\n",
    "    valid_ds = dataset[\"validation\"]\n",
    "    test_ds = dataset[\"test\"]\n",
    "\n",
    "    training_args.logging_steps = len(train_ds) // batch_size\n",
    "    trainer = Trainer(model_init=model_init,\n",
    "                      args=training_args,\n",
    "                      data_collator=data_collator,\n",
    "                      compute_metrics=compute_metrics,\n",
    "                      train_dataset=train_ds,\n",
    "                      eval_dataset=valid_ds)\n",
    "    \n",
    "    trainer.train()\n",
    "    if training_args.push_to_hub:\n",
    "        trainer.push_to_hub(commit_message = \"more_train\")\n",
    "    \n",
    "    f1_score = get_f1_score(trainer, test_ds)   \n",
    "    \n",
    "    return pd.DataFrame.from_dict({\n",
    "        \"num_sample\" : [len(train_ds)], \"f1_score\" : [f1_score]})\n",
    "\n",
    "train_on_subset(encoded_ja, 250)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
