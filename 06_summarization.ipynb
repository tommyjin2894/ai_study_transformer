{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN/DailyMail Dataset 을 이용한 summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", '3.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': Value(dtype='string', id=None),\n",
       " 'highlights': Value(dtype='string', id=None),\n",
       " 'id': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][10][\"article\"][:2000]\n",
    "summarys = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk, sent tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tommy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/tommy/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n",
      "[nltk_data] Downloading package punkt to /home/tommy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/tommy/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.data.path.append('/usr/local/share/nltk_data')\n",
    "\n",
    "# 'punkt' 다운로드 및 찾기\n",
    "nltk.download('popular')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 요약 모델의 baseline\n",
    "- 주로 요약 모델의 baseline **첫 문장 3개**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WASHINGTON (CNN) -- As he awaits a crucial progress report on Iraq, President Bush will try to put a twist on comparisons of the war to Vietnam by invoking the historical lessons of that conflict to argue against pulling out.',\n",
       " 'President Bush pauses Tuesday during a news conference at the  North American Leaders summit in Canada.',\n",
       " 'On Wednesday in Kansas City, Missouri, Bush will tell members of the Veterans of Foreign Wars that \"then, as now, people argued that the real problem was America\\'s presence and that if we would just withdraw, the killing would end,\" according to speech excerpts released Tuesday by the White House.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = dataset[\"train\"][10][\"article\"][:2000]\n",
    "\n",
    "sent_tokenize(test)[:3] # sentance spliting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### str + \"TL;DR\"\n",
    "- too long didn't read\n",
    "- 한국어 버젼으로 \"3 줄 요약좀..\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpt2 for summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "\n",
    "set_seed(42)\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2-xl\")\n",
    "query = test + \"\\nTL;DR\\n\"\n",
    "pip_out = pipe(query, max_length = 512, clean_up_tokenization_spaces = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarys[\"gpt2\"] = pip_out[0][\"generated_text\"].split(\"\\nTL;DR\\n\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5 for summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"t5-large\")\n",
    "pip_out = pipe(test)\n",
    "summarys[\"t5\"]=pip_out[0][\"summary_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt2': \"To be fair, you can't compare this war to prior conflicts in east Asia in the sense that there's a difference between military intervention and war. Also, the president's speech excerpts are not necessarily a full transcript. The White House says it will release the full remarks sometime in the next 2-3 days.\",\n",
       " 't5': 'president bush will try to put a twist on comparisons of the war to Vietnam . he\\'ll tell veterans of foreign war that \"the real problem was America\\'s presence\" \"the price of america\\'s withdrawal was paid by millions of innocent citizens\" speech excerpts released by the white house .'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BART for summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=\"cuda\")\n",
    "pip_out = pipe(test)\n",
    "summarys[\"bart\"]=pip_out[0][\"summary_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt2': \"To be fair, you can't compare this war to prior conflicts in east Asia in the sense that there's a difference between military intervention and war. Also, the president's speech excerpts are not necessarily a full transcript. The White House says it will release the full remarks sometime in the next 2-3 days.\",\n",
       " 't5': 'president bush will try to put a twist on comparisons of the war to Vietnam . he\\'ll tell veterans of foreign war that \"the real problem was America\\'s presence\" \"the price of america\\'s withdrawal was paid by millions of innocent citizens\" speech excerpts released by the white house .',\n",
       " 'bart': \"President Bush to tell Veterans of Foreign Wars about Vietnam War. He will argue withdrawal from Vietnam emboldened terrorists, he will say. Bush will cite Osama bin Laden's quote that U.S. would rise against Iraq war. Senate Majority Leader Harry Reid says comparison ignores difference between wars.\"}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEGASUS for summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\", device=\"cuda\")\n",
    "pip_out = pipe(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarys[\"pegasus\"]=pip_out[0][\"summary_text\"].replace('<n>','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델별 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[grund truth]\n",
      "London (CNN)A 19-year-old man was charged Wednesday with terror offenses after he was arrested as he returned to Britain from Turkey, London's Metropolitan Police said. Yahya Rashid, a UK national from northwest London, was detained at Luton airport on Tuesday after he arrived on a flight from Istanbul, police said. He's been charged with engaging in conduct in preparation of acts of terrorism, and with engaging in conduct with the intention of assisting others to commit acts of terrorism. Both charges relate to the period between November 1 and March 31. Rashid is due to appear in Westminster Magistrates' Court on Wednesday, police said. CNN's Lindsay Isaac contributed to this report. \n",
      "\n",
      "[gpt2]\n",
      "To be fair, you can't compare this war to prior conflicts in east Asia in the sense that there's a difference between military intervention and war. Also, the president's speech excerpts are not necessarily a full transcript. The White House says it will release the full remarks sometime in the next 2-3 days.\n",
      "\n",
      "[t5]\n",
      "president bush will try to put a twist on comparisons of the war to Vietnam . he'll tell veterans of foreign war that \"the real problem was America's presence\" \"the price of america's withdrawal was paid by millions of innocent citizens\" speech excerpts released by the white house .\n",
      "\n",
      "[bart]\n",
      "President Bush to tell Veterans of Foreign Wars about Vietnam War. He will argue withdrawal from Vietnam emboldened terrorists, he will say. Bush will cite Osama bin Laden's quote that U.S. would rise against Iraq war. Senate Majority Leader Harry Reid says comparison ignores difference between wars.\n",
      "\n",
      "[pegasus]\n",
      "President Bush to speak to Veterans of Foreign Wars on Wednesday .Bush to say withdrawing from Vietnam emboldened terrorists by compromising U.S. credibility .Speech excerpts released Tuesday by the White House .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[grund truth]\")\n",
    "print(dataset[\"test\"][10][\"article\"],'\\n')\n",
    "\n",
    "for k,v in summarys.items():\n",
    "    print(f\"[{k}]\")\n",
    "    print(v, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가 (BLEU:Bilingual Evaluation Understudy Score)\n",
    "- 참조 텍스트와 얼마나 많이 정렬되었는지, 단어 or n-gram 을 체크 (:정밀도 에서 비롯된 방법)\n",
    "    - 수정 정밀도($p_n$) 공식\n",
    "        $$ p_n = \\frac{\\sum_{\\text{n-gram} \\in snt'}Count_{\\text{clip}}(\\text{n-gram})}{\\sum_{\\text{n-gram} \\in snt}Count(\\text{n-gram})}$$\n",
    "        에서<br>\n",
    "            $snt$ : **gen** 된 (후보)candidate 문장 <br>\n",
    "            $snt'$ : 참조(reference) 문장 <br>\n",
    "            $\\text{n-gram}$ : 연속된 단어의 조합 <br>\n",
    "            $Count_{\\text{clip}}(\\text{n-gram})$ : 클리핑 된 $\\text{n-gram}$ 의 수(겹치는 $\\text{n-gram}$)<br>\n",
    "            $Count(\\text{n-gram})$ : 생성된 문장의 $\\text{n-gram}$ 갯수 <br>\n",
    "    - 예시 (1-gram)\n",
    "        - ref = \"the cat is on the mat\"\n",
    "        - gen = \"<u>the</u> the the the <u>the</u> the\"\n",
    "\n",
    "        $$  P_{n} = \\frac{\\text{문장 일치수}}{\\text{생성된 총 단어 수}} =  \\frac{2}{6}$$\n",
    "\n",
    "    - 재현 률을 고려한 항 **BR(brevity penalty)** : 즉 생성된 문장이 참조 문장보다 짧은지의 척도, 생성된 문장이 길면 $BR = 1$ 이다\n",
    "        $$BR = \\min(1, e^{1-l_{\\text{ref}}/l_{\\text{gen}}})$$\n",
    "        - 결과 길이를 고려한 항,\n",
    "        - 번역 길이가 짧은경우 P 값이 상승하는 경향이 있어\n",
    "        - 길이가 짧을 경우 패널티를 준다.\n",
    "        - 생성된 길이가 참조 문장보다 길면 1로 반환 한다.\n",
    "    - BLEU-N 점수 계산\n",
    "        - 수정 정밀도의 기하평균 : $$\\left(\\prod_{n=1}^{N} p_n\\right)^{1/N} == \\exp{\\left(\\frac{1}{N}\\prod_{n=1}^{N} \\log p_n \\right)}$$\n",
    "        - BLEU-N 점수 계산 : $$\\text{BLEU-N} = \\text{BR} \\times \\left(\\prod_{n=1}^{N} p_n\\right)^{1/N}$$\n",
    "- 단점 : \n",
    "    - **동의어를** 고려하지 않음\n",
    "    - **토큰화된 텍스트**를 기대한다. <br>\n",
    "        ex.<br>\n",
    "        reference : [I'm a doctor] -> ['I',\"'\",'m',' a','doctor']<br>\n",
    "        candidate : [I am a doctor] -> ['I',' am',' a','doctor']<br>\n",
    "        에서 I'm 과 I am 은 동의어로 치부하지 않게 된다. 또한 토큰 길이도 다르게 될 수 있어 이에 대한 패널티를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install evaluate\n",
    "# !pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{BLEU-N} = \\text{BR} \\times \\left(\\prod_{n=1}^{N} p_n\\right)^{1/N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.0, 'precisions': [0.3333333333333333, 0.0, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 6, 'reference_length': 6}\n"
     ]
    }
   ],
   "source": [
    "# 1-gram test\n",
    "import evaluate\n",
    "bleu= evaluate.load(\"bleu\")\n",
    "\n",
    "\n",
    "ref = \"the cat is on the mat\"\n",
    "can = \"the the the the the the\"\n",
    "\n",
    "b_result =bleu.compute(predictions=[can], references=[ref])\n",
    "print(b_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-N              (bleu                ):0.4264014327112209\n",
      "p                   (precisions          ):[0.5, 0.36363636363636365]\n",
      "BP                  (brevity_penalty     ):1.0\n",
      "BR                  (length_ratio        ):2.0\n",
      "len_gen             (translation_length  ):12\n",
      "len_ref             (reference_length    ):6\n",
      "\n",
      "생성된 문장의 길이가 참조 문장보다 길다.\n",
      "BR => 1 로 계산된다\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#n-gram test\n",
    "bleu= evaluate.load(\"bleu\")\n",
    "\n",
    "ref = \"the cat is on the mat\"\n",
    "# can = \"the the the the the the\"\n",
    "can_for_2_gram = \"the cat the the the is on the mat mat mat mat\"\n",
    "\n",
    "b_result =bleu.compute(predictions=[can_for_2_gram], references=[ref], max_order = 2) # max_order 로 n-gram 을 정해준다.\n",
    "for f,(k,v) in zip([\"BLEU-N\",\"p\",\"BP\", \"BR\",\"len_gen\",\"len_ref\"],b_result.items()):\n",
    "    print(f\"{f:20s}({k:20s}):{v}\")\n",
    "\n",
    "print(\"\"\"\n",
    "생성된 문장의 길이가 참조 문장보다 길다.\n",
    "BR => 1 로 계산된다\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 25.211936184349828,\n",
       " 'counts': [6, 4, 2, 1],\n",
       " 'totals': [12, 11, 10, 9],\n",
       " 'precisions': [50.0, 36.36363636363637, 20.0, 11.11111111111111],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 12,\n",
       " 'ref_len': 6}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sacre bleu : 토큰화 단계를 내제화\n",
    "\n",
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "sb_result = sacrebleu.compute(predictions=[can_for_2_gram], references=[ref])\n",
    "sb_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가 (ROUGE:Recall-Oriented Understudy for Gisting Evaluation)\n",
    "- ROUGE-N Recall(참조 문장) 기반 $$ \\text{ROUGE-N} = \\frac{\\sum_{\\text{n-gram} \\in \\text{ref}} \\min(\\text{Count}_{\\text{gen}}(\\text{n-gram}), \\text{Count}_{\\text{ref}}(\\text{n-gram}))}{\\sum_{\\text{n-gram} \\in \\text{ref}} \\text{Count}_{\\text{ref}}(\\text{n-gram})}$$\n",
    "    $$ \\frac{\\text{모든 참조 문장의 <n-gram과 생성문장의 n-gram 중 최솟값 들>의 합}}{\\text{모든 참조 문장의 <n-gram 의 경우의 수>의 합}}$$\n",
    "\n",
    "- ROUGE-N Precision (생성된 문장) 기반 $$ \\text{ROUGE-N} = \\frac{\\sum_{\\text{n-gram} \\in \\text{gen}} \\min(\\text{Count}_{\\text{gen}}(\\text{n-gram}), \\text{Count}_{\\text{ref}}(\\text{n-gram}))}{\\sum_{\\text{n-gram} \\in \\text{gen}} \\text{Count}_{\\text{gen}}(\\text{n-gram})}$$\n",
    "\n",
    "- ROUGE-N f-1 score $$ \\text{f1-score} = \\frac{2 \\times \\text{precision} \\times \\text{recall}}{\\text{preciaion} + \\text{recall}}$$\n",
    "\n",
    "    > BLUE 와의 비교 $$\\text{BLEU-N} = \\min(1, e^{1-l_{\\text{ref}}/l_{\\text{gen}}}) \\times \\prod_{n=1}^{N} \\left( \\frac{\\sum_{\\text{n-gram} \\in snt'}Count_{\\text{clip}}(\\text{n-gram})}{\\sum_{\\text{n-gram} \\in snt}Count(\\text{n-gram})} \\right)^{1/N}$$\n",
    "\n",
    "- ROUGE-L\n",
    "    - LCS 점수 (Longest Common Subsequence : 가장 긴 공통 시퀀스)\n",
    "        - 문자열 기준 에서 비교가 가능 (\"<u>appl</u>e\" and \"<u>appl</u>ication\")\n",
    "        - $\\text{X} = \\text{*appl*e}$ 와 $\\text{Y} = \\text{*appl*ication}$ 에서\n",
    "          $$\\text{LCS(X,Y)} = 4$$\n",
    "          $$R_{\\text{LCS}} = \\frac{\\text{LCS(X,Y)}}{m} = \\frac{4}{5}$$\n",
    "          $$P_{\\text{LCS}} = \\frac{\\text{LCS(X,Y)}}{n} = \\frac{4}{11}$$\n",
    "          $$F_{\\text{LCS}} = \\frac{(1 + \\beta^2) R_{\\text{LCS}} P_{\\text{LCS}}}{R_{\\text{LCS}} + P_{\\text{LCS}}}$$\n",
    "            - 만약 $\\beta = 1$ 일때 기존 **f1-score** 공식이랑 동일 <br>(`transformer` 는 $\\beta = 1$ 로 계산)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- meteor 및 rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE\n",
      "{'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "r_result = rouge.compute(predictions=[can], references=[ref])\n",
    "print(\"ROUGE\")\n",
    "print(r_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.160920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080460</td>\n",
       "      <td>0.080460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0.179641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107784</td>\n",
       "      <td>0.107784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.072289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.134228</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.080537</td>\n",
       "      <td>0.080537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rouge1    rouge2    rougeL  rougeLsum\n",
       "gpt2     0.160920  0.000000  0.080460   0.080460\n",
       "t5       0.179641  0.000000  0.107784   0.107784\n",
       "bart     0.096386  0.000000  0.072289   0.072289\n",
       "pegasus  0.134228  0.013605  0.080537   0.080537"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'전반적으로 pegasus 의 성능이 좋다'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "all_scores = {}\n",
    "\n",
    "for k,v in summarys.items():\n",
    "    scores = rouge.compute(references=[dataset[\"test\"][10][\"article\"]],predictions=[v])\n",
    "    all_scores[k] = scores\n",
    "\n",
    "display(pd.DataFrame(all_scores).T)\n",
    "\"전반적으로 pegasus 의 성능이 좋다\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 참고 meteor 스코어 $$\\text{METEOR} = \\frac{10 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\times \\left(1 - \\frac{\\text{Penalty}}{\\text{len}} \\right)$$\n",
    "\n",
    "    여기서\n",
    "    $$\\text{Precision} = \\frac{\\text{LCS}(X,Y)}{m}$$\n",
    "    $$\\text{Recall} = \\frac{\\text{LCS}(X,Y)}{n}$$\n",
    "    $$\\text{Penalty} = n_{\\text{chunk}} - 1$$\n",
    "    - chunk 의 기준\n",
    "        - 생성문, 참조문 단어 순서 일치 부분\n",
    "        - 완전히 일치하는 경우 패널티 = 0\n",
    "        - 일치하는 chunk 가 많아 질 수록 패널티 증가\n",
    "        - 즉 순서차이가 큰 문장에서 패널티 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/tommy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/tommy/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/tommy/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************************************************************************************************************************************\n",
      "{'meteor': 0.16666666666666666}\n"
     ]
    }
   ],
   "source": [
    "metero = evaluate.load(\"meteor\")\n",
    "m_result = metero.compute(predictions=[can], references=[ref])\n",
    "print(\"*\"*200)\n",
    "print(m_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the the the the the the'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEGASUS 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", '3.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = dataset[\"test\"].shuffle(seed=42).select(range(1800))\n",
    "test_data = test_data.map(lambda x: {\"article\": x[\"article\"][:2000]}) # 너무 길어서 글자수 제한\n",
    "test_data = test_data.map(lambda x: {\"three_sentence_summaries\": \".\".join(x[\"article\"].split(\".\")[:3])}) # 베이스 라인 모델 : 처음 3개의 문장 (요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data[\"article\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 6/6 [1:11:28<00:00, 714.82s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pegasus 모델 로드\n",
    "pegasus = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\", device=0)\n",
    "\n",
    "\n",
    "def predict_pegasus_batch(batch):\n",
    "    summaries = pegasus(batch[\"article\"])\n",
    "    batch[\"summary_text\"] = [summary[\"summary_text\"] for summary in summaries]\n",
    "    return batch\n",
    "\n",
    "# 데이터 배치 크기 설정\n",
    "batch_size = 300\n",
    "\n",
    "# 배치 처리\n",
    "batched_results = []\n",
    "for i in tqdm(range(0, len(test_data), batch_size)):\n",
    "    batch = test_data[i:i+batch_size]\n",
    "    batched_results.append(predict_pegasus_batch(batch))\n",
    "\n",
    "final_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 병합\n",
    "for key in batched_results[0].keys():\n",
    "    inst_list =[]\n",
    "    for i in range(len(batched_results)):\n",
    "        inst_list.append(batched_results[i][key])\n",
    "    final_results[key] = inst_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "def eval_rouge(preds, refs):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    rouge.add_batch(predictions=preds, references=refs)\n",
    "    r_result = rouge.compute()\n",
    "    return r_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_sentence_summaries_ = [i[0].replace(\"\\n\",\" \") for i in final_results[\"three_sentence_summaries\"]]\n",
    "summary_text_ = [i[0].replace(\"\\n\",\" \") for i in final_results[\"summary_text\"]]\n",
    "highlights_ = [i[0].replace(\"\\n\",\" \") for i in final_results[\"highlights\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.338175</td>\n",
       "      <td>0.166377</td>\n",
       "      <td>0.227477</td>\n",
       "      <td>0.227477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.384581</td>\n",
       "      <td>0.207907</td>\n",
       "      <td>0.290122</td>\n",
       "      <td>0.290222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.338175  0.166377  0.227477   0.227477\n",
       "pegasus   0.384581  0.207907  0.290122   0.290222"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(data=[eval_rouge(three_sentence_summaries_, highlights_),\n",
    "                   eval_rouge(summary_text_, highlights_)],\n",
    "            index=[\"baseline\", \"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rouge 점수는 일정수준 정확도와 관련이 없다.\n",
    "- Rouge 점수는 디코딩 전략과 관련이 있다.\n",
    "- Rouge 와 Bleu 점수보다는 사람의 판단이 더욱 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 삼성의 SAMsum Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 삼성의 데이터셋 이용 ([SAMsum dataset](https://huggingface.co/datasets/Samsung/samsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install py7zr : 7z 압축 파일 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "samsum_dataset = load_dataset(\"samsum\")\n",
    "samsum_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neville: Hi there, does anyone remember what date I got married on?\n",
      "Don: Are you serious?\n",
      "Neville: Dead serious. We're on vacation, and Tina's mad at me about something. I have a strange suspicion that this might have something to do with our wedding anniversary, but I have nowhere to check.\n",
      "Wyatt: Hang on, I'll ask my wife.\n",
      "Don: Haha, someone's in a lot of trouble :D\n",
      "Wyatt: September 17. I hope you remember the year ;)\n",
      "**************************************************\n",
      "Wyatt reminds Neville his wedding anniversary is on the 17th of September. Neville's wife is upset and it might be because Neville forgot about their anniversary.\n"
     ]
    }
   ],
   "source": [
    "print(samsum_dataset[\"train\"][5][\"dialogue\"])\n",
    "print(\"*\"*50)\n",
    "print(samsum_dataset[\"train\"][5][\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pegasus = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\", device=0);\n",
    "test_result = pegasus(samsum_dataset[\"test\"][5][\"dialogue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference : \n",
      "\n",
      "Wyatt reminds Neville his wedding anniversary is on the 17th of September. Neville's wife is upset and it might be because Neville forgot about their anniversary.\n",
      "**************************************************\n",
      "prediction with no train : \n",
      "\n",
      "Benjamin and Hilary are having lunch with some French people .\n",
      "Then they'll head to La Cantina for some Italian cuisine .\n",
      "And then they'll take the keys and take a nap .\n"
     ]
    }
   ],
   "source": [
    "ref = samsum_dataset[\"train\"][5][\"summary\"]\n",
    "pre = test_result[0][\"summary_text\"].replace(\"<n>\",\"\\n\")\n",
    "print(\"reference : \\n\")\n",
    "print(ref)\n",
    "print(\"*\"*50)\n",
    "print(\"prediction with no train : \\n\")\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE\n",
      "{'rouge1': 0.06779661016949153, 'rouge2': 0.0, 'rougeL': 0.06779661016949153, 'rougeLsum': 0.06779661016949153}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "r_result = rouge.compute(predictions=[pre], references=[ref])\n",
    "print(\"ROUGE\")\n",
    "print(r_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEGASUS 파인튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 입출력 길이 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-cnn_dailymail\")\n",
    "dia_lens = [len(tokenizer.encode(i)) for i in samsum_dataset[\"train\"][\"dialogue\"]]\n",
    "sum_lens = [len(tokenizer.encode(i)) for i in samsum_dataset[\"train\"][\"summary\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "\n",
    "sns.histplot(dia_lens, bins=20, ax = axes[0])\n",
    "axes[0].set_title(\"dialogue length\"), axes[0].set_xlabel(\"count\"), axes[0].set_ylabel(\"token count\")\n",
    "sns.histplot(sum_lens, bins=20, ax = axes[1])\n",
    "axes[1].set_title(\"summary length\"), axes[1].set_xlabel(\"count\") , axes[1].set_ylabel(\"token count\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 전처리 (with collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b903cb1c746441389a106a7c7a528fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e351922847c4187854bc116c858acf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_examples_to_features(batch):\n",
    "    # 입력 값의 토큰화\n",
    "    input_encodings = tokenizer(batch[\"dialogue\"], max_length=1024, truncation=True)\n",
    "    \n",
    "    # 정답 라벨의 토큰화 : T5 계열은 정답과 입력과의 형식의 차이가 있다.\n",
    "        # OUTDATED\n",
    "        # with tokenizer.as_target_tokenizer():\n",
    "        #     target_encodings = tokenizer(batch[\"summary\"], max_length=128, truncation=True)\n",
    "        # ------\n",
    "    target_encodings = tokenizer(text_target=batch[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    return {\"input_ids\" : input_encodings[\"input_ids\"],\n",
    "            \"attention_mask\" : input_encodings[\"attention_mask\"],\n",
    "            \"labels\": target_encodings[\"input_ids\"]}\n",
    "\n",
    "samsum_dataset_train = samsum_dataset[\"train\"].map(convert_examples_to_features, batched=True)\n",
    "samsum_dataset_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "samsum_dataset_valid = samsum_dataset[\"validation\"].map(convert_examples_to_features, batched=True)\n",
    "samsum_dataset_valid.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "samsum_dataset_test = samsum_dataset[\"test\"].map(convert_examples_to_features, batched=True)\n",
    "samsum_dataset_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tommy/anaconda3/envs/transformer/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForSeq2Seq, TrainingArguments\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=\"google/pegasus-cnn_dailymail\")\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=\"pegasus-samsum\",\n",
    "    num_train_epochs=1,\n",
    "    warmup_steps=500,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    push_to_hub=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    gradient_accumulation_steps=16 # 누적 그레디언트\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Accumulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 장점\n",
    "    - GPU 제한이 있을때 유리하다.\n",
    "    - 배치 크기가 커지면 더욱 정확한 결과.\n",
    "    - 더 큰 모델을 학습 가능하게 해준다\n",
    "- 단점\n",
    "    - 훈련 속도 저하\n",
    "    - 최적화가 비효율적으로 수행된다. (긴 업데이트)\n",
    "- training_arg 에서의 그래디언트 축적 설명\n",
    "    ```python\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16\n",
    "    ```\n",
    "    - 배치 크기를 1으로 처리하고, 그래디언트를 누적한다.\n",
    "    - steps = 16 이므로 16 스텝을 처리한 후 그레디언트 계산 밑 누적(파라미터 업데이트)\n",
    "- 수식\n",
    "    - 경사 하강법 : $$\\theta = \\theta - \\eta \\cdot \\nabla_{\\theta} L(\\theta)$$\n",
    "        - 여기서는 배치 1 씩 경사하강\n",
    "    - 축적 : $$G_{\\text{accum}} = \\sum_{i=1}^{k} \\nabla_{\\theta} L_i(\\theta)$$\n",
    "    - 파라미터 업데이트 : $$ \\theta = \\theta - \\eta \\cdot \\frac{1}{k} \\cdot G_{\\text{accum}} $$\n",
    "    - 여기서 $k$ 는 `per_device_train_batch_size`\n",
    "    - 만약 `batch_size=4` 일때 총 `4*16 = 64` 개의 샘플이후 그래디언트를 평균 내어 업데이트를 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import json\n",
    "\n",
    "with open(\"hf_key_token.json\") as f:\n",
    "    token = json.load(f)[\"hf_key_token\"]\n",
    "\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_6519/45702053.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/pegasus-cnn_dailymail\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model, args = train_args,\n",
    "    tokenizer = tokenizer, data_collator = data_collator,\n",
    "    train_dataset = samsum_dataset_train,\n",
    "    eval_dataset = samsum_dataset_valid\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tommy/anaconda3/envs/transformer/lib/python3.11/site-packages/transformers/data/data_collator.py:657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='920' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [920/920 1:40:29, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.666900</td>\n",
       "      <td>1.483606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tommy/anaconda3/envs/transformer/lib/python3.11/site-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=920, training_loss=1.8309065518171892, metrics={'train_runtime': 6137.6084, 'train_samples_per_second': 2.4, 'train_steps_per_second': 0.15, 'total_flos': 5528248038285312.0, 'train_loss': 1.8309065518171892, 'epoch': 0.9991854466467553})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pegasus = pipeline(\"summarization\", model=\"tommyjin/pegasus-samsum\", device=0)\n",
    "predicted_from_test = pegasus(samsum_dataset_test[\"dialogue\"])\n",
    "predicted_from_test = [summary_text[\"summary_text\"] for summary_text in predicted_from_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trained_pegasus</th>\n",
       "      <td>0.439675</td>\n",
       "      <td>0.212841</td>\n",
       "      <td>0.351656</td>\n",
       "      <td>0.351494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   rouge1    rouge2    rougeL  rougeLsum\n",
       "trained_pegasus  0.439675  0.212841  0.351656   0.351494"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(data=[eval_rouge(predicted_from_test, samsum_dataset_test[\"summary\"])],\n",
    "            index=[\"trained_pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실제 예측 상황을 보고 결정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Wanda wants to make a party. Gina will take Wanda's father's car and go do groceries with her. Wanda will ask Gina on Friday.\",\n",
       " \"Wanda wants to throw a party. She asks Gina to borrow her father's car and go do groceries together. They set the date for Friday. \")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "predicted_from_test[i], samsum_dataset_test[\"summary\"][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 직접 판단한 결과 잘 요약 되었다는 것을 알수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finetunning 결과\n",
    "\n",
    "- predicted :\n",
    "    Wanda wants to make a party. <br>\n",
    "    Gina will take Wanda's father's car and go do groceries with her. <br>\n",
    "    Wanda will ask Gina on Friday.\" <br>\n",
    "\n",
    "- label :\n",
    "    Wanda wants to throw a party. <br>\n",
    "    She asks Gina to borrow her father's car and go do groceries together. <br>\n",
    "    They set the date for Friday. <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
